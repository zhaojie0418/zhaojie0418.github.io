

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="深入理解JAVA虚拟机第二章：java内存区域和内存溢出异常  程序计数器部分：  如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地（Native）方法，这个计数器值则应为空（Undefined）此内存区域是唯一一个在《Java虚拟机规范》中没有规定任何OutOfMemoryError情况的区域·   栈帧（Stack Frame）用于">
<meta property="og:type" content="article">
<meta property="og:title" content="fluid">
<meta property="og:url" content="http://example.com/2022/10/13/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="fluid">
<meta property="og:description" content="深入理解JAVA虚拟机第二章：java内存区域和内存溢出异常  程序计数器部分：  如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地（Native）方法，这个计数器值则应为空（Undefined）此内存区域是唯一一个在《Java虚拟机规范》中没有规定任何OutOfMemoryError情况的区域·   栈帧（Stack Frame）用于">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221119222233318.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221120151423921.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221120151434004.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221120153930160.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221121165159996.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221121165405966.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221123193014729.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221123202904830.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126173040784.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221201173858863.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125203607563.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125203205479.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221128104046824.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221128144957798.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221128145018987.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125192746870.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125194107906.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125200903780.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125194122388.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125200921258.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126130001272.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126125628190.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126125826690.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126125054413.png">
<meta property="og:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126161740653.png">
<meta property="article:published_time" content="2022-10-13T12:33:18.950Z">
<meta property="article:modified_time" content="2023-03-05T08:20:11.734Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221119222233318.png">
  
  
  
  <title>fluid</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text=""></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-10-13 20:33" pubdate>
          2022年10月13日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          45k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          377 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none"></h1>
            
            
              <div class="markdown-body">
                
                <h1 id="深入理解JAVA虚拟机"><a href="#深入理解JAVA虚拟机" class="headerlink" title="深入理解JAVA虚拟机"></a>深入理解JAVA虚拟机</h1><h2 id="第二章：java内存区域和内存溢出异常"><a href="#第二章：java内存区域和内存溢出异常" class="headerlink" title="第二章：java内存区域和内存溢出异常"></a>第二章：java内存区域和内存溢出异常</h2><p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221119222233318.png" srcset="/img/loading.gif" lazyload alt="image-20221119222233318"></p>
<ul>
<li><p>程序计数器部分：</p>
<ul>
<li>如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地（Native）方法，这个计数器值则应为空（Undefined）此内存区域是唯一一个在《Java虚拟机规范》中没有规定任何OutOfMemoryError情况的区域·</li>
</ul>
</li>
<li><p>栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息</p>
</li>
<li><p>对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置，不止是指针）</p>
</li>
<li><p>局部变量表中还存放了returnAddress类型（指向了一条字节码指令的地址）</p>
</li>
<li><p>局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。请读者注意，这里说的“大小”是指变量槽的数量，虚拟机真正使用多大的内存空间（譬如按照1个变量槽占用32个比特、64个比特，或者更多）来实现一个变量槽，这是完全由具体的虚拟机实现自行决定的事情</p>
</li>
<li><p>如果栈支持动态扩展，则当栈扩展无法申请到足够内存则会报错OOM</p>
</li>
<li><p>随着逃逸分析技术，栈上分配和标量替换等技术使得对象分配在堆中并不绝对化</p>
</li>
<li><p>分代并不是堆的固定“称呼”，只是HotSpot使用的垃圾回收器的流行导致的刻板印象</p>
</li>
<li><p>如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java堆细分的目的只是为了更好地回收内存，或者更快地分配内存</p>
</li>
<li><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。虽然《Java虚拟机规范》中把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫作“非堆”（Non-Heap），目的是与Java堆区分开来</p>
</li>
<li><p>永久代（所谓永久只是因为这部分的垃圾回收不好操作，类卸载也很严格，但的确需要回收）只是HotSpot对于方法区的一种实现，其他虚拟机并没有这个区域，只是为了使得HotSpot的垃圾回收器能够像管理java堆一样管理方法区，由于其本身更容易产生内存溢出的问题，到了java8中将永久代中的类型信息移动到由本地内存实现的元空间中</p>
</li>
<li><p><strong>运行时常量池（Runtime Constant Pool）是方法区的一部分</strong>。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中</p>
</li>
<li><p>运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法</p>
</li>
<li><p>在JDK 1.4中新加入了NIO（New Input&#x2F;Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I&#x2F;O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据</p>
</li>
<li><p>对象的分配方式</p>
<ul>
<li>指针碰撞（Bump ThePointer）：假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离<ul>
<li>使用场景：当使用Serial、ParNew等带压缩整理过程的收集器时，系统采用的分配算法是指针碰撞，既简单又高效</li>
</ul>
</li>
<li>空闲列表（Free List）：虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录<ul>
<li>使用场景：用CMS这种基于清除（Sweep）算法的收集器时，理论上就只能采用较为复杂的空闲列表来分配内存</li>
</ul>
</li>
</ul>
</li>
<li><p>分配内存可能产生并发（争抢同一块内存）的解决方法：</p>
<ul>
<li>对分配内存空间的动作进行同步处理——实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性</li>
<li>把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local AllocationBuffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX：+&#x2F;-UseTLAB参数来设定</li>
</ul>
</li>
<li><p>内存分配完成后需要对分配好的内存空间（除对象头）全都初始化为0，这步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，使程序能访问到这些字段的数据类型所对应的零值</p>
</li>
<li><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了。但是从Java程序的视角看来，对象创建才刚刚开始——构造函数，即Class文件中的<init>()方法还没有执行，所有的字段都为默认的零值，对象需要的其他资源和状态信息也还没有按照预定的意图构造好。一般来说（由字节码流中new指令后面是否跟随invokespecial指令所决定，Java编译器会在遇到new关键字的地方同时生成这两条字节码指令，但如果直接通过其他方式产生的则不一定如此），new指令之后会接着执行<init>()方法，按照程序员的意愿对对象进行初始化，这样一个真正可用的对象才算完全被构造出来</p>
</li>
<li><p>对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）</p>
<ul>
<li>对象头的组成部分<ul>
<li>Mark Word ：用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32个比特和64个比特</li>
<li>类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身</li>
<li>（如果这个对象是数组）对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是如果数组的长度是不确定的，将无法通过元数据中的信息推断出数组的大小</li>
</ul>
</li>
</ul>
</li>
<li><p>对象的定位方式</p>
<ul>
<li>句柄访问</li>
<li>使用句柄来访问的最大好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改</li>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221120151423921.png" srcset="/img/loading.gif" lazyload alt="image-20221120151423921"></li>
<li>直接指针访问</li>
<li>优点：使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本，就本书讨论的主要虚拟机HotSpot而言，它<strong>主要使用第二种</strong>方式进行对象访问</li>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221120151434004.png" srcset="/img/loading.gif" lazyload alt="image-20221120151434004"></li>
</ul>
</li>
<li><p>Java的线程是映射到操作系统的内核线程上，无限制地创建线程会对操作系统带来很大压力，上述代码执行时有很高的风险，可能会由于创建线程数量过多而导致操作系统假死</p>
</li>
<li><p>OOM的不同情况分析</p>
<ul>
<li>堆溢出<ul>
<li>使用内存映像分析工具对堆转储快照进行分析，判断是内存泄漏还是内存溢出，<ul>
<li>内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链，找到泄漏对象是通过怎样的引用路径、与哪些GC Roots相关联，才导致垃圾收集器无法回收它们，根据泄漏对象的类型信息以及它到GC Roots引用链的信息，一般可以比较准确地定位到这些对象创建的位置，进而找出产生内存泄漏的代码的具体位置</li>
<li>内存溢出，检查Java虚拟机的堆参数（-Xmx与-Xms）设置，与机器的内存对比，看看是否还有向上调整的空间。再从代码上检查是否存在某些对象生命周期过长、持有状态时间过长、存储结构设计不合理等情况，尽量减少程序运行期的内存消耗</li>
</ul>
</li>
</ul>
</li>
<li>java虚拟机栈溢出&#x2F;本地方法栈溢出<ul>
<li>无论是由于栈帧太大还是虚拟机栈容量太小，当新的栈帧内存无法分配的时候，HotSpot虚拟机抛出的都是StackOverflowError异常，但是如果运行动态扩展栈的大小则报错OOM</li>
</ul>
</li>
<li>方法区和运行时常量池溢出<ul>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221120153930160.png" srcset="/img/loading.gif" lazyload alt="image-20221120153930160"></li>
</ul>
</li>
<li>随着Spring框架等动态生成类的大量使用，导致方法区容易溢出，但是随着java8将类数据移动到元空间中，即类导致的内存溢出不容易出现</li>
</ul>
</li>
</ul>
<h2 id="第三章：垃圾收集器与内存分配策略"><a href="#第三章：垃圾收集器与内存分配策略" class="headerlink" title="第三章：垃圾收集器与内存分配策略"></a>第三章：垃圾收集器与内存分配策略</h2><ul>
<li><p>一般不考虑线程独占的内存部分的数据回收，因为随线程而灭，栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由即时编译器进行一些优化，但在基于概念模型的讨论里，大体上可以认为是编译期可知的）</p>
</li>
<li><p>引用计数法简单高效但是需要很多额外的工作才能保证其工作正常运行（循环引用）</p>
</li>
<li><p>目前广泛使用可达性分析算法，使用GCroots进行判断</p>
</li>
<li><p>除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，<strong>如果进行局部回收，某个区域里的对象完全有可能被位于堆中其他区域的对象所引用</strong>，这时候就需要将这些关联区域的对象也一并加入GC Roots集合中去，才能保证可达性分析的正确性</p>
</li>
<li><p>常见引用分类</p>
<ul>
<li>强引用：永远不回收，传统的引用定义</li>
<li>软引用：有用但不必须，在即将报错内存溢出时，会把软引用的对象纳入回收范围内进行回收，如果还是不够才报错</li>
<li>弱引用：只能活到下次垃圾回收前</li>
<li>虚引用：虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知</li>
</ul>
</li>
<li><p>对象回收的完整过程（至少进行两次标记）</p>
<ul>
<li>可达性分析GCRoots标记，若其没有相连的引用链则进行第一次标记</li>
<li>随后进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。假如对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过（这句话的含义在于，如果该对象通过finalize方法逃脱过一次垃圾回收，那么下一次垃圾回收就没办法使用这个逃脱方法了），那么虚拟机将这两种情况都视为“没有必要执行“</li>
<li>如果这个对象被判定为确有必要执行finalize()方法，那么该对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的Finalizer线程去执行它们的finalize()方法。这里所说的“执行”是指虚拟机会<strong>触发</strong>这个方法开始运行，但并不承诺一定会等待它运行结束（如果某个对象的finalize()方法执行缓慢，或者更极端地发生了死循环，将很可能导致F-Queue队列中的其他对象永久处于等待，甚至导致整个内存回收子系统的崩溃）</li>
<li>finalize()方法是对象逃脱死亡命运的最后一次机会，稍后收集器将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的要被回收了</li>
</ul>
</li>
<li><p>对于方法区的垃圾回收</p>
<ul>
<li>JVM虚拟机规范中甚至不要求对方法区进行垃圾回收事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK 11时期的ZGC收集器就不支持类卸载）（但对于方法区的回收实际上有是有必要的，在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及OSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力）</li>
<li>在Java堆中，尤其是在新生代中，对常规应用进行一次垃圾收集通常可以回收70%至99%的内存空间，相比之下，方法区回收囿于苛刻的判定条件，其区域垃圾收集的回收成果往往远低于此</li>
</ul>
</li>
<li><p>方法区的垃圾收集主要回收两部分内容：废弃的常量和不再使用的类型</p>
</li>
<li><p>类卸载的三个前提（之所以是前提是因为就算满足了也不一定回收）</p>
<ul>
<li>Java堆中不存在该类及其任何派生子类的实例</li>
<li>加载该类的类加载器已经被回收（很难满足）</li>
<li>该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法</li>
</ul>
</li>
<li><p>建立分代回收机制（分代本身越来越暴露缺陷）的三个前提假说</p>
<ul>
<li>弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的</li>
<li>强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡</li>
<li>跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数（实际上是前面两个假说的推论，因为强分代最终会因为引用了弱分代而把它拉到老年代中）</li>
</ul>
</li>
<li><p>跨代引用的解决方法</p>
<ul>
<li>我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用，只需在新生代上建立一个全局的数据结构（该结构被称为“记忆集”，Remembered Set），这个结构把老年代划分成若干小块，标识出老年代的哪一块内存会存在跨代引用。此后当发生Minor GC时，只有包含了跨代引用的小块内存里的对象才会被加入到GCRoots进行扫描。虽然这种方法需要在对象改变引用关系（如将自己或者某个属性赋值）时维护记录数据的正确性，会增加一些运行时的开销，但比起收集时扫描整个老年代来说仍然是划算的</li>
</ul>
</li>
<li><p>垃圾回收分类</p>
<ul>
<li>部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分为：<ul>
<li>新生代收集（Minor GC&#x2F;Young GC）：指目标只是新生代的垃圾收集</li>
<li>老年代收集（Major GC&#x2F;Old GC）：指目标只是老年代的垃圾收集。<strong>目前只有CMS收集器会有单独收集老年代的行为。</strong>另外请注意“Major GC”这个说法现在有点混淆，在不同资料上常有不同所指，读者需按上下文区分到底是指老年代的收集还是整堆收集</li>
<li>混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。<strong>目前只有G1收集器会有这种行为</strong></li>
</ul>
</li>
<li>整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集</li>
</ul>
</li>
<li><p><strong>垃圾回收算法</strong></p>
<ul>
<li><p><strong>标记清除算法</strong></p>
<ul>
<li>缺点：<ul>
<li>第一个是<strong>执行效率不稳定</strong>，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记（标记所有）和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低；</li>
<li>第二个是<strong>内存空间的碎片化</strong>问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>标记复制算法</strong>（正如其字面意思：半区复制）</p>
<ul>
<li>优点：内存分配简单，只需要在栈顶指针进行移动即可，不会有内存碎片的问题</li>
<li>缺点：只使用了一半的内存，并且当需要保存的对象很多时，内存复制开销大</li>
<li>适用场景：新生代的垃圾回收（由于新生代的对象短命，故每次内存复制的开销少）<ul>
<li>PS：同样的这样的算法显然不适合老年代回收，因为老年代往往大量不会被回收，新生代的那点担保空间完全不足以承担老年代的容量</li>
</ul>
</li>
<li>优化算法：“Appel式回收”<ul>
<li><strong>HotSpot虚拟机的Serial、ParNew等新生代收集器均采用了这种策略来设计新生代的内存布局</strong>[1]。Appel式回收的具体做法是把新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存只使用Eden和其中一块Survivor。发生垃圾搜集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也即每次新生代中可用内存空间为整个新生代容量的90%（Eden的80%加上一个Survivor的10%），只有一个Survivor空间，即10%的新生代是会被“浪费”的。</li>
<li>特殊情况下需要保留的对象超过10%时，因此Appel式回收还有一个充当罕见情况的“<strong>逃生门</strong>”的安全设计，当Survivor空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保（Handle Promotion），即额外的部分直接进入老年代</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>标记整理算法</strong></p>
<ul>
<li>缺点：移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作，而且这种对象移动操作必须全程暂停用户应用程序才能进行，即“Stop The World”</li>
<li>适用场景：老年代垃圾回收</li>
<li>优化算法：对于老年代的回收可以通过移动来腾出内存，也可以使用<strong>分区空闲分配链表</strong>来解决内存分配问题，但是两者各有利弊移动则内存回收时会更复杂，不移动则内存分配时会更复杂。从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但是从整个程序的吞吐量来看，移动对象会更划算。此语境中，吞吐量的实质是<strong>赋值器与收集器</strong>的效率总和。即使不移动对象会使得收集器的效率提升一些，但因<strong>内存分配和访问相比垃圾收集频率要高得多</strong>，这部分的耗时增加，<strong>总吞吐量仍然是下降的</strong>。HotSpot虚拟机里面关注吞吐量的ParallelScavenge收集器是基于标记-整理算法的，而关注延迟的CMS收集器则是基于标记-清除算法的<ul>
<li>另外，还有一种<strong>“和稀泥式”</strong>解决方案可以不在内存分配和访问上增加太大额外负担，做法是让虚拟机<strong>平时多数时间都采用标记-清除算法，暂时容忍内存碎片的存在</strong>，直到内存空间的碎片化程度已经大到影响对象分配时，<strong>再采用标记-整理算法收集一次，以获得规整的内存空间</strong>。前面提到的基于标记-清除算法的CMS收集器面临空间碎片过多时采用的就是这种处理办法</li>
</ul>
</li>
</ul>
</li>
<li><p>根结点枚举的难处：Java应用越做越庞大，光是方法区的大小就常有数百上千兆，里面的类、常量等更是恒河沙数，若要逐个检</p>
<p>查以这里为起源的引用肯定得消耗不少时间</p>
</li>
<li><p>枚举根结点是一定要STW的，即使是所谓的并发分析也只是在一个具有一致性（枚举期间引用关系不能改变）的快照中进行的</p>
</li>
<li><p>虚拟机中并不是完全从GCroot开始分析的，虚拟机中有OopMap的数据结构用于存放对象引用</p>
</li>
<li><p>安全点：</p>
<ul>
<li>HotSpot也的确没有为每条指令都生成OopMap，前面已经提到，只是在“特定的位置”记录了这些信息，这些位置被称为安全点（Safepoint）</li>
<li>用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是强制要求必须执行到达安全点后才能够暂停。因此，安全点的选定既不能太少以至于让收集器等待时间过长，也不能太过频繁以至于过分增大运行时的内存负荷。安全点位置的选取基本上是以“是否具有让程序长时间执行的特征”为标准进行选定的，“长时间执行”的最明显特征就是指令序列的复用，例如方法调用、循环跳转、异常跳转等都属于指令序列复用，所以只有具有这些功能的指令才会产生安全点</li>
<li>确保每个线程都达到安全的方式<ul>
<li>抢先式中断（Preemptive Suspension）抢先式中断不需要线程的执行代码主动去配合，在垃圾收集发生时，系统首先所有用户线程全部中断，如果发现有用户线程中断的地方不在安全点上，就恢复这条线程执行，让它一会再重新中断，直到跑到安全点上。<strong>现在几乎没有虚拟机实现采用抢先式中断来暂停线程响应GC事件</strong></li>
<li>主动式中断的思想是当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。<strong>轮询标志的地方和安全点是重合的，另外还要加上所有创建对象和其他需要在Java堆上分配内存的地方，这是为了检查是否即将要发生垃圾收集，避免没有足够内存分配新对象。</strong></li>
</ul>
</li>
<li>HotSpot使用内存保护陷阱的方式，把轮询操作精简至只有一条汇编指令的程度。下面代码清单3-4中的test指令就是HotSpot生成的轮询指令，当需要暂停用户线程时，虚拟机把0x160100的内存页设置为不可读，那线程执行到test指令时就会产生一个自陷异常信号，然后在预先注册的异常处理器中挂起线程实现等待，这样仅通过一条汇编指令便完成安全点轮询和触发线程中断了</li>
<li>安全区域：<ul>
<li>用户线程处于Sleep状态或者Blocked状态由于没有时间片，不能再走到安全的地方去中断挂起自己，虚拟机也显然不可能持续等待线程重新被激活分配处理器时间</li>
<li>安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。<strong>我们也可以把安全区域看作被扩展拉伸了的安全点</strong></li>
<li>当用户线程执行到安全区域里面的代码时，首先会标识自己已经进入了安全区域，那样当这段时间里虚拟机要发起垃圾收集时就不必去管这些已声明自己在安全区域内的线程了。当线程要离开安全区域时，它要检查虚拟机是否已经完成了根节点枚举（或者垃圾收集过程中其他需要暂停用户线程的阶段），如果完成了，那线程就当作没事发生过，继续执行；否则它就必须一直等待，直到收到可以离开安全区域的信号为止</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>TODO：记忆表卡表到垃圾回收器期间</p>
</li>
<li><p>java垃圾回收中<strong>并发和并行</strong>的定义</p>
<ul>
<li>并行（Parallel）：并行描述的是多条垃圾收集器线程之间的关系，说明同一时间有多条这样的线程在协同工作，通常默认此时用户线程是处于等待状态</li>
<li>并发（Concurrent）：并发描述的是垃圾收集器线程与用户线程之间的关系，说明同一时间垃圾收集器线程与用户线程都在运行。由于用户线程并未被冻结，所以程序仍然能响应服务请求，但由于垃圾收集器线程占用了一部分系统资源，此时应用程序的处理的吞吐量将受到一定影响</li>
</ul>
</li>
<li><p>经典垃圾回收器</p>
<ul>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221121165159996.png" srcset="/img/loading.gif" lazyload alt="image-20221121165159996"></li>
<li><strong>Serial 垃圾回收器</strong><ul>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221121165405966.png" srcset="/img/loading.gif" lazyload alt="image-20221121165405966"></li>
<li>优点：HotSpot虚拟机运行在客户端模式下的默认新生代收集器，有着优于其他收集器的地方，那就是<strong>简单而高效</strong>（与其他收集器的单线程相比）<ul>
<li><strong>物理机内存受限的情况：</strong>对于内存资源受限的环境，它是所有收集器里<strong>额外内存消耗（Memory Footprint）最小的</strong>；</li>
<li><strong>单核处理器情况：</strong>对于单核处理器或处理器核心数较少的环境来说，Serial收集器由于<strong>没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率</strong></li>
<li><strong>应用本身占用空间少的情况：</strong>在用户桌面的应用场景以及近年来流行的部分微服务应用中，分配给虚拟机管理的内存一般来说并不会特别大，收集几十兆甚至一两百兆的新生代（仅仅是指新生代使用的内存，桌面应用甚少超过这个容量），垃圾收集的停顿时间完全可以控制在十几、几十毫秒，最多一百多毫秒以内，只要不是频繁发生收集，这点停顿时间对许多用户来说是完全可以接受的</li>
</ul>
</li>
</ul>
</li>
<li><strong>ParNew收集器</strong><ul>
<li>实质上是Serial收集器的多线程并行版本，除了同时使用多条线程进行垃圾收集之外，其余的行为包括Serial收集器可用的所有控制参数（例如：-XX：SurvivorRatio、-XX：PretenureSizeThreshold、-XX：HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一致，在实现上这两种收集器也共用了相当多的代码</li>
<li>优点：不少运行在服务端模式下的HotSpot虚拟机<ul>
<li>除了Serial收集器外，目前只有它能与CMS收集器配合工作</li>
<li>当处理器多核并且开启了很多线程时比Serial收集器效果更好</li>
</ul>
</li>
<li>缺点：ParNew收集器在单核心处理器的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程（Hyper-Threading）技术实现的伪双核处理器环境中都不能百分之百保证超越Serial收集器。当然，随着可以被使用的处理器核心数量的增加，ParNew对于垃圾收集时系统资源的高效利用还是很有好处的。它默认开启的收集线程数与处理器核心数量相同，在处理器核心非常多（譬如32个，现在CPU都是多核加超线程设计，服务器达到或超过32个逻辑核心的情况非常普遍）的环境中</li>
</ul>
</li>
<li><strong>Parallel Scavenge收集器：</strong>也是一款新生代收集器，它同样是基于标记-复制算法实现的收集器，也是能够并行收集的多线程收集器，Parallel Scavenge的诸多特性从表面上看和ParNew非常相似<ul>
<li>特点：Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值</li>
<li>适用场景：停顿时间越短就越适合需要与用户交互或需要保证服务响应质量的程序，良好的响应速度能提升用户体验；而高吞吐量则可以最高效率地利用处理器资源，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的分析任务</li>
<li>调节参数：Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，<ul>
<li>控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数</li>
<li>直接设置吞吐量大小的-XX：GCTimeRatio参数</li>
<li>自动优化参数-XX：+UseAdaptiveSizePolicy值得我们关注。这是一个开关参数，当这个参数被激活之后，就不需要人工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX：SurvivorRatio）、晋升老年代对象大小（-XX：PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。这种调节方式称为垃圾收集的自适应的调节策略（GC Ergonomics）</li>
</ul>
</li>
<li>和ParNew的区分：<ul>
<li>Parallel Scavenge注重吞吐量而非相应时间</li>
<li>自适应调节策略也是Parallel Scavenge收集器区别于ParNew收集器的一个重要特性</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221123193014729.png" srcset="/img/loading.gif" lazyload alt="image-20221126173040784"></p>
<ul>
<li><p><strong>Serial Old收集器：</strong>是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法(特征类似Serial )</p>
<ul>
<li>适用场景：<ul>
<li>供客户端模式下的HotSpot虚拟机使用</li>
<li>在服务端情况下作为CMS收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Parallel Old收集器：</strong>是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现</p>
<ul>
<li>适用场景：<strong>在注重吞吐量或者处理器资源较为稀缺的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器这个组合</strong></li>
</ul>
</li>
<li><p><strong>CMS（Concurrent Mark Sweep）收集器：</strong>是一种以获取最短回收停顿时间为目标的收集器</p>
<ul>
<li>适用场景：互联网网站或者基于浏览器的B&#x2F;S系统的服务端上（关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来良好的交互体验）</li>
<li>使用步骤<ul>
<li>初始标记（CMS initial mark）  “<strong>Stop The World”</strong><ul>
<li>只是标记一下GCRoots能直接关联到的对象，速度很快</li>
</ul>
</li>
<li>并发标记（CMS concurrent mark）<ul>
<li>从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行</li>
</ul>
</li>
<li>重新标记（CMS remark）        <strong>“Stop The World”</strong><ul>
<li>修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短</li>
</ul>
</li>
<li>并发清除（CMS concurrent sweep）<ul>
<li>清理删除掉标记阶段判断的已经死亡的对象，由于<strong>不需要移动存活对象</strong>，所以这个阶段也是可以与用户线程同时并发的</li>
</ul>
</li>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221123202904830.png" srcset="/img/loading.gif" lazyload alt="image-20221123202904830"></li>
</ul>
</li>
<li>优点：<ul>
<li>并发收集、低停顿</li>
</ul>
</li>
<li>缺点：<ul>
<li><strong>CMS收集器对处理器资源非常敏感</strong>（配置要求高）。事实上，面向并发设计的程序都对处理器资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分线程（或者说处理器的计算能力）而导致应用程序变慢，降低总吞吐量。CMS默认启动的回收线程数是（处理器核心数量+3）&#x2F;4，也就是说，如果处理器核心数在四个或以上，并发回收时垃圾收集线程只占用不超过25%的处理器运算资源，并且会随着处理器核心数量的增加而下降。但是当处理器核心数量不足四个时，CMS对用户程序的影响就可能变得很大。<strong>如果应用本来的处理器负载就很高，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然大幅降低</strong>。为了缓解这种情况，虚拟机提供了一种称为“增量式并发收集器”在并发标记、清理的时候让收集器线程、用户线程交替运行，尽量减少垃圾收集线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得较少一些，直观感受是速度变慢的时间更多了，但速度下降幅度就没有那么明显。实践证明增量式的CMS收集器效果很一般，从JDK 7开始，i-CMS模式已经被声明为“deprecated”，即已过时不再提倡用户使用，<strong>到JDK 9发布后i-CMS模式被完全废弃</strong></li>
<li><strong>由于CMS收集器无法处理“浮动垃圾”（Floating Garbage），有可能出现“Con-current ModeFailure”失败进而导致另一次完全“Stop The World”的Full GC的产生</strong>。在CMS的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为“浮动垃圾”。<strong>同样也是由于在垃圾收集阶段用户线程还需要持续运行，那就还需要预留足够内存空间提供给用户线程使用，因此CMS收集器不能像其他收集器那样等待到老年代几乎完全被填满了再进行收集，必须预留一部分空间供并发收集时的程序运作使用。在JDK5的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在实际应用中老年代增长并不是太快，可以适当调高参数-XX：CMSInitiatingOccu-pancyFraction的值来提高CMS的触发百分比，降低内存回收频率，获取更好的性能。到了JDK 6时，CMS收集器的启动阈值就已经默认提升至92%。</strong>但这又会更容易面临另一种风险：要是CMS运行期间<strong>预留的内存无法满足程序分配新对象的需要</strong>，就会出现一次“并发失败”（Concurrent Mode Failure），这时候虚拟机将不得不启动后备预案：冻结用户线程的执行，<strong>临时启用Serial Old收集器</strong>来重新进行老年代的垃圾收集，但这样停顿时间就很长了。所以参数-XX：CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量的并发失败产生，性能反而降低，用户应在生产环境中根据实际应用情况来权衡设置</li>
<li><strong>CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦</strong>，往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况。为了解决这个问题，CMS收集器提供了一个-XX：+UseCMS-CompactAtFullCollection开关参数（默认是开启的，此参数从JDK 9开始废弃），用于在CMS收集器不得不进行Full GC时开启内存碎片的合并整理过程，由于这个内存整理必须移动存活对象，（在Shenandoah和ZGC出现前）是无法并发的。这样空间碎片问题是解决了，但停顿时间又会变长，因此虚拟机设计者们还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction（此参数从JDK 9开始废弃），这个参数的作用是要求CMS收集器在执行过若干次（数量由参数值决定）不整理空间的Full GC之后，下一次进入Full GC前会先进行碎片整理（默认值为0，表示每次进入Full GC时都进行碎片整理）</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Garbage First（简称G1）收集器：</strong></p>
<ul>
<li><p>G1是一款主要面向服务端应用的垃圾收集器。HotSpot开发团队最初赋予它的期望是（在比较长期的）未来可以替换掉JDK 5中发布的CMS收集器。现在这个期望目标已经实现过半了，JDK 9发布之日，G1宣告取代Parallel Scavenge加Parallel Old组合，成为服务端模式下的默认垃圾收集器，而CMS则沦落至被声明为不推荐使用（Deprecate）的收集器</p>
</li>
<li><p>作为CMS收集器的替代者和继承人，设计者们希望做出一款能够建立起“停顿时间模型”（PausePrediction Model）的收集器，停顿时间模型的意思是能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标，这几乎已经是实时Java（RTSJ）的中软实时垃圾收集器特征了</p>
</li>
<li><p>特点：</p>
<ul>
<li>以面向堆内存任何部分来组成<strong>回收集（Collection Set，一般简称CSet）</strong>进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式</li>
<li><strong>G1开创的基于Region的堆内存布局是它能够面向堆内存任何部分回收的关键，</strong>把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果</li>
<li><strong>Region中还有一类特殊的Humongous区域，专门用来存储大对象</strong>。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。每个Region的大小可以通过参数-XX：G1HeapRegionSize设定，取值范围为1MB～32MB，且应为2的N次幂。而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分来进行看待</li>
<li><strong>虽然G1仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了，</strong>它们都是一系列区域（不需要连续）的动态集合。G1收集器之所以能建立可预测的停顿时间模型，是因为它<strong>将Region作为单次回收的最小单元</strong>，即每次收集到的内存空间都是Region大小的整数倍，这样可以<strong>有计划地避免在整个Java堆中进行全区域的垃圾收集</strong>。更具体的处理思路是让<strong>G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小</strong>，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间（使用参数-XX：MaxGCPauseMillis指定，默认值是200毫秒），优先处理回收价值收益最大的那些Region，这也就是“Garbage First”名字的由来。这种使用Region划分内存空间，以及具有优先级的区域回收方式，保证了G1收集器在有限的时间内获取尽可能高的收集效率</li>
<li>并非纯粹地追求低延迟，官方给它设定的目标是<strong>在延迟可控的情况下获得尽可能高的吞吐量</strong>（即更多的去追求回收速率而不是追求回收百分比，只要能够满足内存分配的速度即可）</li>
<li><strong>可以由用户指定期望的停顿时间是G1收集器很强大的一个功能</strong>，设置不同的期望停顿时间，可使得G1在不同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。不过，这里设置的“期望值”必须是符合实际的，不能异想天开，毕竟G1是要冻结用户线程来复制对象的，这个停顿时间再怎么低也得有个限度。它默认的停顿目标为两百毫秒，一般来说，回收阶段占到几十到一百甚至接近两百毫秒都很正常，但如果我们把停顿时间调得非常低，譬如设置为二十毫秒，很可能出现的结果就是由于停顿目标时间太短，导致每次选出来的回收集只占堆内存很小的一部分，收集器收集的速度逐渐跟不上分配器分配的速度，导致垃圾慢慢堆积。很可能一开始收集器还能从空闲的堆内存中获得一些喘息的时间，但应用运行时间一长就不行了，最终占满堆引发Full GC反而降低性能，所以通常把期望停顿时间设置为一两百毫秒或者两三百毫秒会是比较合理的</li>
</ul>
</li>
<li><p><strong>实现过程中解决问题的方式：</strong></p>
<ul>
<li>将Java堆分成多个独立Region后，Region里面存在的<strong>跨Region引用对象如何解决？</strong>解决的思路我们已经知道：使用记忆集避免全堆作为GC Roots扫描，但在<strong>G1收集器上记忆集的应用其实要复杂很多，它的每个Region都维护有自己的记忆集，这些记忆集会记录下别的Region指向自己的指针</strong>，并标记这些指针分别在哪些卡页的范围之内。G1的记忆集在存储结构的本质上是一种哈希表，Key是别的Region的起始地址，Value是一个集合，里面存储的元素是卡表的索引号。这种“双向”的卡表结构（卡表是“我指向谁”，这种结构还记录了“谁指向我”）比原来的卡表实现起来更复杂，同时由于Region数量比传统收集器的分代数量明显要多得多，因此G1收集器要比其他的传统垃圾收集器有更高的内存占用负担。根据经验，<strong>G1至少要耗费大约相当于Java堆容量10%至20%的额外内存来维持收集器工作。</strong></li>
<li><strong>在并发标记阶段如何保证收集线程与用户线程互不干扰地运行？</strong>这里首先要解决的是用户线程改变对象引用关系时，须保证其不能打破原本的对象图结构，导致标记结果出现错误，该问题的解决办法笔者已经抽出独立小节来讲解过（见3.4.6节）：<strong>CMS收集器采用增量更新算法实现，而G1收集器则是通过原始快照（SATB）算法来实现的。</strong>此外，垃圾收集对用户线程的影响还体现在回收过程中新创建对象的内存分配上，程序要继续运行就肯定会持续有新对象被创建，G1为每一个Region设计了两个名为TAMS（Top at Mark Start）的指针，<strong>把Region中的一部分空间划分出来用于并发回收过程中的新对象分配，并发回收时新分配的对象地址都必须要在这两个指针位置以上。G1收集器默认在这个地址以上的对象是被隐式标记过的，即默认它们是存活的，不纳入回收范围</strong>。<strong>与CMS中的“Concurrent Mode Failure”失败会导致Full GC类似，如果内存回收的速度赶不上内存分配的速度，G1收集器也要被迫冻结用户线程执行，导致Full GC而产生长时间“Stop The World”</strong></li>
<li><strong>怎样建立起可靠的停顿预测模型？</strong>用户通过-XX：MaxGCPauseMillis参数指定的停顿时间只意味着垃圾收集发生之前的期望值，但G1收集器要怎么做才能满足用户的期望呢？<strong>G1收集器的停顿预测模型是以衰减均值（Decaying Average）为理论基础来实现的，在垃圾收集过程中，G1收集器会记录每个Region的回收耗时、每个Region记忆集里的脏卡数量等各个可测量的步骤花费的成本，并分析得出平均值、标准偏差、置信度等统计信息</strong>。这里<strong>强调的“衰减平均值”是指它会比普通的平均值更容易受到新数据的影响，平均值代表整体平均状态，但衰减平均值更准确地代表“最近的”平均状态。换句话说，Region的统计状态越新越能决定其回收的价值</strong>。然后通过这些信息预测现在开始回收的话，由哪些Region组成回收集才可以在不超过期望停顿时间的约束下获得最高的收益</li>
</ul>
</li>
<li><p>执行过程的分析（如果我们不去计算用户线程运行过程中的动作（如使用写屏障维护记忆集的操作），G1收集器的运作过程大致可划分为以下四个步骤）：</p>
<ul>
<li><strong>初始标记（Initial Marking）：</strong>  “<strong>Stop The World”</strong><ul>
<li>仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。这个阶段需要停顿线程，但耗时很短，而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际并没有额外的停顿。</li>
</ul>
</li>
<li><strong>并发标记（Concurrent Marking）：</strong>    <ul>
<li>从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB（原始快照）记录下的在并发时有引用变动的对象。</li>
</ul>
</li>
<li><strong>最终标记（Final Marking）：</strong>    “<strong>Stop The World”</strong><ul>
<li>对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录</li>
</ul>
</li>
<li><strong>筛选回收（Live Data Counting and Evacuation）： **    “</strong>Stop The World”**<ul>
<li>负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。这里的操作<strong>涉及存活对象的移动，是必须暂停用户线程</strong>，由多条收集器线程并行完成的。（CMS基于标记清除，不需要移动对象，自然不用STW）</li>
<li>PS：回收阶段（Evacuation）其实本也有想过设计成与用户程序一起并发执行，但这件事情做起来比较复杂，考虑到G1只是回收一部分Region，停顿时间是用户可控制的，所以并不迫切去实现，而选择把这个特性放到了G1之后出现的低延迟垃圾收集器（即ZGC）中。另外，还考虑到G1不是仅仅面向低延迟，<strong>停顿用户线程能够最大幅度提高垃圾收集效率，为了保证吞吐量所以才选择了完全暂停用户线程的实现方案</strong></li>
</ul>
</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126173040784.png" srcset="/img/loading.gif" lazyload alt="image-20221201173858863"></p>
</li>
<li><p><strong>CMS垃圾回收器和G1垃圾回收器比较</strong></p>
<ul>
<li><strong>G1 的优点：****相比CMS，G1的优点有很多，暂且不论可以指定最大停顿时间、分Region的内存布局、按收益动态确定回收集这些创新性设计带来的红利，单从最传统的算法理论上看，G1也更有发展潜力</strong>与CMS的“标记-清除”算法不同，G1从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个Region之间）上看又是基于“标记-复制”算法实现，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，垃圾收集完成之后能提供规整的可用内存。这种特性有利于程序长时间运行，在程序为大对象分配内存时不容易因无法找到连续内存空间而提前触发下一次收集</li>
<li><strong>CMS的优点：</strong>虽然G1和CMS都使用卡表来处理跨代指针，但G1的卡表实现更为复杂，而且堆中每个Region，无论扮演的是新生代还是老年代角色，都必须有一份卡表，这导致G1的记忆集（和其他内存消耗）可能会占整个堆容量的20%乃至更多的内存空间；相比起来CMS的卡表就相当简单，只有唯一一份，而且只需要处理老年代到新生代的引用，反过来则不需要，由于新生代的对象具有朝生夕灭的不稳定性，引用变化频繁，能省下这个区域的维护开销是很划算的</li>
<li><strong>在执行负载的角度上</strong>，同样由于两个收集器各自的细节实现特点导致了用户程序运行时的负载会有不同，譬如它们都使用到写屏障，<strong>CMS用写后屏障来更新维护卡表；而G1除了使用写后屏障</strong>来进行同样的（由于G1的卡表结构复杂，其实是更烦琐的）卡表维护操作外，为了实现原始快照搜索（SATB）算法，还需要使用写前屏障来跟踪并发时的指针变化情况。相比起增量更新算法，原始快照搜索能够减少并发标记和重新标记阶段的消耗，避免CMS那样在最终标记阶段停顿时间过长的缺点，但是在用户程序运行过程中确实会产生由跟踪引用变化带来的额外负担。由于G1对写屏障的复杂操作要比CMS消耗更多的运算资源，所以CMS的写屏障实现是直接的同步操作，而G1就不得不将其实现为类似于消息队列的结构，把写前屏障和写后屏障中要做的事情都放到队列里，然后再异步处理。</li>
<li><strong>总结：在小内存应用上CMS的表现大概率仍然要会优于G1，而在大内存应用上G1则大多能发挥其优势，这个优劣势的Java堆容量平衡点通常在6GB至8GB之间</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>TODO （剩余部分省略）</p>
</li>
</ul>
<h2 id="第六章：类文件结构"><a href="#第六章：类文件结构" class="headerlink" title="第六章：类文件结构"></a>第六章：类文件结构</h2><p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221201173858863.png" srcset="/img/loading.gif" lazyload alt="image-20221123193014729"></p>
<ul>
<li><p>class文件由两部分组成：无符号数和表（更准确的说，class文件的一部分即为常量池，而常量池中的所有数据项都可以看做是“_info”结尾的表，而这些表又由其他表或者基本数据类型所组成）</p>
<ul>
<li>无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。</li>
<li>表是由多个无符号数或者其他表作为数据项构成的复合数据类型，为了便于区分，所有表的命名都习惯性地以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上也可以视作是一张表，这张表由表6-1所示的数据项按严格顺序排列构成</li>
</ul>
</li>
<li><p>由于class文件没有任何分割符，所以必须保证其长度的确定性</p>
</li>
<li><p>UTF-8缩略编码与普通UTF-8编码的区别是：（尽可能的省）</p>
<ul>
<li>从’\u0001’到’\u007f’之间的字符（相当于1～127的ASCII码）的缩略编码使用一个字节表示，从’\u0080’到’\u07ff’之间的所有字符的缩略编码用两个字节表示，从’\u0800’开始到’\uffff’之间的所有字符的缩略编码就按照普通UTF-8编码规则使用三个字节表示</li>
</ul>
</li>
<li><p>类文件中的数据指向可以看做是连环嵌套的格式，比如下图类索引指向常量池中的类info，而类info中的字面量又指向utf8_info</p>
</li>
<li><p>相比于全限定名和简单名称，方法和字段的描述符就要复杂一些。描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值</p>
<ul>
<li>对于数组类型，每一维度将使用一个前置的“[”字符来描述，如一个定义为“java.lang.String[][]”类型的二维数组将被记录成“[[Ljava&#x2F;lang&#x2F;String；”，一个整型数组“int[]”将被记录成“[I”。</li>
<li>用描述符来描述方法时，按照先参数列表、后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“()”之内。如方法void inc()的描述符为“()V”，方法java.lang.String toString()的描述符为“()Ljava&#x2F;lang&#x2F;String；”，方法int indexOf(char[]source，int sourceOffset，int sourceCount，char[]target，int targetOffset，int targetCount，int fromIndex)的描述符为“([CII[CIII)I”</li>
</ul>
</li>
<li><p>方法表中本身没有code，其具体代码存放在方法属性表中</p>
<ul>
<li>方法的定义可以通过访问标志、名称索引、描述符索引来表达清楚，但方法里面的代码去哪里了？方法里的Java代码，经过Javac编译器编译成字节码指令之后，存放在方法属性表集合中一个名为“Code”的属性里面，属性表作为Class文件格式中最具扩展性的一种数据项目，将在下一节中详细讲解。</li>
</ul>
</li>
<li><p>在Java语言中，要重载（Overload）一个方法，除了要与原方法具有相同的简单名称之外，还要求必须拥有一个与原方法不同的特征签名[2]。特征签名是指一个方法中各个参数在常量池中的字段符号引用的集合，也正是因为返回值不会包含在特征签名之中，所以Java语言里面是无法仅仅依靠返回值的不同来对一个已有方法进行重载的。但是在Class文件格式之中，特征签名的范围明显要更大一些，只要描述符不是完全一致的两个方法就可以共存。也就是说，如果两个方法有相同的名称和特征签名，但返回值不同，那么也是可以合法共存于同一个Class文件中的</p>
</li>
<li><p>与Class文件中其他的数据项目要求严格的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格顺序，并且《Java虚拟机规范》允许只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略掉它不认识的属性</p>
</li>
</ul>
<h2 id="第十章：前端编译和优化（TODO学完编译原理后学习）"><a href="#第十章：前端编译和优化（TODO学完编译原理后学习）" class="headerlink" title="第十章：前端编译和优化（TODO学完编译原理后学习）"></a>第十章：前端编译和优化（TODO学完编译原理后学习）</h2><ul>
<li><strong>java中的编译的”多种解释”</strong><ul>
<li>前端编译器（叫“编译器的前端”更准确一些）把*.java文件转变成*.class文件的过程；<ul>
<li>JDK的Javac（C++语言（包含少量C语言））、Eclipse JDT中的增量式编译器（ECJ）</li>
</ul>
</li>
<li>Java虚拟机的即时编译器（常称JIT编译器，Just In Time Compiler）运行期把字节码转变成本地机器码的过程；<ul>
<li>HotSpot虚拟机的C1、C2编译器，Graal编译器</li>
</ul>
</li>
<li>使用静态的提前编译器（常称AOT编译器，Ahead Of Time Compiler）直接把程序编译成与目标机器指令集相关的二进制代码的过程<ul>
<li>JDK的Jaotc、GNU Compiler for the Java（GCJ）[2]、Excelsior JET</li>
</ul>
</li>
</ul>
</li>
<li>前端编译实际上在后期的优化是微乎其微的，选择把对性能的优化全部集中到运行期的即时编译器中，这样可以让那些不是由Javac产生的Class文件（如JRuby、Groovy等语言的Class文件）也同样能享受到编译器优化措施所带来的性能红利</li>
<li><strong>java采用解释器和编译器并行的结构</strong><ul>
<li>解释器优点：<ul>
<li>当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即运行（编译器要想获取优化程度更好的代码自然要编译更长的时间）</li>
<li>内存角度：当程序运行环境中内存资源限制较大，可以使用解释执行节约内存（如部分嵌入式系统中和大部分的JavaCard应用中就只有解释器的存在）</li>
</ul>
</li>
<li>编译器优点<ul>
<li>随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码，这样可以减少解释器的中间损耗，获得更高的执行效率</li>
<li>内存角度：如果内存相对充裕，可以使用编译执行来提升效率</li>
</ul>
</li>
<li>解释器作为编译器的逃生门（编译器做错事的后备选择）<ul>
<li>解释器还可以作为<strong>编译器激进优化时后备的“逃生门”</strong>（如果情况允许，HotSpot虚拟机中也会采用不进行激进优化的客户端编译器充当“逃生门”的角色），让编译器根据概率选择一些不能保证所有情况都正确，但大多数时候都能提升运行速度的优化手段，当激进优化的假设不成立，如加载了新类以后，类型继承结构出现变化、出现“罕见陷阱”（Uncommon Trap）时可以通过逆优化（Deoptimization）退回到解释状态继续执行，因此在整个Java虚拟机执行架构里，解释器与编译器经常是相辅相成地配合工作，其交互关系如图11-1所示。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十一章：后端编译和优化"><a href="#第十一章：后端编译和优化" class="headerlink" title="第十一章：后端编译和优化"></a>第十一章：后端编译和优化</h2><ul>
<li><p>即时编译器编译热点代码</p>
<ul>
<li>当虚拟机发现某个方法或代码块的运行特别频繁，就会把这些代码认定为“热点代码”（Hot Spot Code），为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成本地机器码，并以各种手段尽可能地进行代码优化</li>
</ul>
</li>
<li><p><strong>即时编译器分类</strong></p>
<ul>
<li>C1编译器——“客户端编译器”（Client Compiler）</li>
<li>C2编译器——“服务端编译器”（Server Compiler）</li>
<li>Graal编译器（JDK 10出现，目的用于替代C2编译器，Graal编译器目前还处于实验状态）</li>
</ul>
</li>
<li><p>java虚拟机默认情况都是编译器和解释器一同工作</p>
<ul>
<li>“-client”或“-server”参数去强制指定虚拟机运行在客户端模式还是服务端模式（决定使用C1还是C2）</li>
<li>“-Xint”强制虚拟机运行于“解释模式”（Interpreted Mode），这时候编译器完全不介入工作，全部代码都使用解释方式执行</li>
<li>“-Xcomp”强制虚拟机运行于“编译模式”（Compiled Mode），这时候将优先采用编译方式执行程序，但是解释器仍然要在编译无法进行的情况下介入执行过程</li>
</ul>
</li>
<li><p><strong>分层编译</strong></p>
<ul>
<li>第0层。程序纯解释执行，并且解释器不开启性能监控功能（Profiling）</li>
<li>第1层。使用（C1）客户端编译器将字节码编译为本地代码来运行，进行简单可靠的稳定优化，不开启性能监控功能</li>
<li>第2层。仍然使用客户端编译器执行，仅开启方法及回边次数统计等有限的性能监控功能</li>
<li>第3层。仍然使用客户端编译器执行，开启全部性能监控，除了第2层的统计信息外，还会收集如分支跳转、虚方法调用版本等全部的统计信息</li>
<li>第4层。使用服务端编译器将字节码编译为本地代码，相比起客户端编译器，服务端编译器会启用更多编译耗时更长的优化，还会根据性能监控信息进行一些不可靠的激进优化</li>
<li>不同情况下的分层编译</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125203607563.png" srcset="/img/loading.gif" lazyload alt="image-20221128104046824"></p>
</li>
<li><p>分层编译的好处</p>
<ul>
<li>实施分层编译后，解释器、客户端编译器和服务端编译器就会同时工作，热点代码都可能会被多次编译，用客户端编译器获取更高的编译速度，用服务端编译器来获取更好的编译质量，在解释执行的时候也无须额外承担收集性能监控信息的任务，而在服务端编译器采用高复杂度的优化算法时，客户端编译器可先采用简单优化来为它争取更多的编译时间</li>
</ul>
</li>
<li><p>热点代码主要为：<strong>多次调用的方法，多次执行的循环体</strong></p>
<ul>
<li>对于这两种情况，<strong>编译的目标对象都是整个方法体，而不会是单独的循环体</strong>。第一种情况，由于是依靠方法调用触发的编译，那编译器理所当然地会以整个方法作为编译对象，这种编译也是虚拟机中标准的即时编译方式。而对于后一种情况，尽管编译动作是由循环体所触发的，热点只是方法的一部分，但编译器依然必须以整个方法作为编译对象，只是执行入口（从方法第几条字节码指令开始执行）会稍有不同，编译时会传入执行入口点字节码序号（Byte Code Index，BCI）。这种编译方式因为编译发生在方法执行的过程中，因此被很形象地称为<strong>“栈上替换”（On Stack Replacement，OSR）</strong>，即方法的栈帧还在栈上，方法就被替换了</li>
</ul>
</li>
<li><p>热点探测判定：（两者在虚拟机的不同实现中都有应用）</p>
<ul>
<li><p>基于采样的热点探测（Sample Based Hot Spot Code Detection）</p>
<ul>
<li>采用这种方法的虚拟机会周期性地检查各个线程的调用栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法”。基于采样的热点探测的好处是实现简单高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可），缺点是<strong>很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测</strong>。</li>
</ul>
</li>
<li><p>基于计数器的热点探测（Counter Based Hot Spot Code Detection）</p>
<ul>
<li><strong>采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器</strong>，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法”。这种统计方法实现起来要麻烦一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系。但是它的统计结果相对来说更加精确严谨。</li>
<li>方法调用计数器（Invocation Counter）</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125203205479.png" srcset="/img/loading.gif" lazyload alt="image-20221128144957798"></p>
<ul>
<li>回边计数器（Back Edge Counter“回边”的意思就是指在循环边界往回跳转）<ul>
<li><strong>在字节码中遇到控制流向后跳转的指令就称为“回边（Back Edge）”，很显然建立回边计数器统计的目的是为了触发栈上的替换编译</strong></li>
</ul>
</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221128104046824.png" srcset="/img/loading.gif" lazyload alt="image-20221128145018987"></p>
<ul>
<li><strong>当一个方法被调用时</strong>，虚拟机会先检查该方法是否存在被即时编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在已被编译过的版本，则将该方法的调用计数器值加一，然后判断<strong>方法调用计数器与回边计数器值之和</strong>是否超过方法调用计数器的阈值。一旦已超过阈值的话，将会向即时编译器提交一个该方法的代码编译请求</li>
<li><strong>当解释器遇到一条回边指令时</strong>，会先查找将要执行的代码片段是否有已经编译好的版本，如果有的话，它将会优先执行已编译的代码，否则就把回边计数器的值加一，然后判断方法调用计数器与回边计数器值之和是否超过回边计数器的阈值。当超过阈值的时候，将会提交一个栈上替换编译请求，并且把回边计数器的值稍微降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果</li>
<li>（程序是并行执行的而并不是傻傻的等着编译器）如果没有做过任何设置，执行引擎默认不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被即时编译器编译完成。当编译工作完成后，这个方法的调用入口地址就会被系统自动改写成新值，下一次调用该方法时就会使用已编译的版本了</li>
</ul>
</li>
<li><p>计数的衰减</p>
<ul>
<li>方法调用计数器：统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间之内方法被调用的次数。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那该方法的调用计数器就会被减少一半，这个过程被称为方法调用计数器热度的衰减（Counter Decay），而这段时间就称为此方法统计的半衰周期（Counter Half Life Time），进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的</li>
<li>回边计数器：与方法计数器不同，回边计数器没有计数热度衰减的过程，因此这个计数器统计的就是该方法循环执行的绝对次数。当计数器溢出的时候，它还会把方法计数器的值也调整到溢出状态，这样下次再进入该方法的时候就会执行标准编译过程</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>编译过程</strong>（TODO 11.2.3）</p>
</li>
<li><p><strong>提前编译</strong></p>
<ul>
<li>现在提前编译产品和对其的研究有着两条明显的分支，<ul>
<li><strong>传统静态</strong>：一条分支是做与传统C、C++编译器类似的，在程序运行之前把程序代码编译成机器码的静态翻译工作；<ul>
<li>这是传统的提前编译应用形式，它在Java中存在的价值直指即时编译的最大弱点：<strong>即时编译要占用程序运行时间和运算资源</strong>，而提前编译由于提前性，所以可以使用大量的时间来进行优化</li>
</ul>
</li>
<li><strong>动态缓存</strong>：另外一条分支是把原本即时编译器在运行时要做的编译工作提前做好并保存下来，下次运行到这些代码（譬如公共库代码在被同一台机器其他Java进程使用）时直接把它加载进来使用<ul>
<li>本质是给即时编译器做缓存加速，去改善Java程序的启动时间，以及需要一段时间预热后才能到达最高性能的问题。这种提前编译被称为动态提前编译（DynamicAOT）或者索性就大大方方地直接叫即时编译缓存（JIT Caching）</li>
<li>动态缓存存在的<strong>弊端</strong>为：提前编译方式不仅要和目标机器相关，甚至还必须与HotSpot虚拟机的运行时参数绑定，以及其为了提高本身的兼容性，无法做一些激进的优化操作</li>
</ul>
</li>
</ul>
</li>
<li>由于提前编译可以有重负荷的编译过程优势，但是<strong>JIT依旧尤其独特的优势</strong><ul>
<li><strong>性能分析制导优化（Profile-Guided Optimization，PGO）</strong>上一节介绍HotSpot的即时编译器时就多次提及在解释器或者客户端编译器运行过程中，会不断收集性能监控信息，譬如某个程序点抽象类通常会是什么实际类型、条件判断通常会走哪条分支、方法调用通常会选择哪个版本、循环通常会进行多少次等，这些数据一般在静态分析时是无法得到的，或者不可能存在确定且唯一的解，最多只能依照一些启发性的条件去进行猜测。但在动态运行时却能看出它们具有非常明显的偏好性。如果一个条件分支的某一条路径执行特别频繁，而其他路径鲜有问津，那就可以把热的代码集中放到一起，集中优化和分配更好的资源（分支预测、寄存器、缓存等）给它</li>
<li><strong>激进预测性优化（Aggressive Speculative Optimization）</strong>，这也已经成为很多即时编译优化措施的基础。静态优化无论如何都必须保证优化后所有的程序外部可见影响（不仅仅是执行结果）与优化前是等效的，如果性能监控信息能够支持它做出一些正确的可能性很大但无法保证绝对正确的预测判断，就已经可以大胆地按照高概率的假设进行优化，万一真的走到罕见分支上，大不了退回到低级编译器甚至解释器上去执行，并不会出现无法挽救的后果。只要出错概率足够低，这样的优化往往能够大幅度降低目标程序的复杂度</li>
<li><strong>链接时优化（Link-Time Optimization，LTO）</strong>，Java语言天生就是动态链接的，一个个Class文件在运行期被加载到虚拟机内存当中，然后在即时编译器里产生优化后的本地代码，这类事情在Java程序员眼里看起来毫无违和之处。但如果类似的场景出现在使用提前编译的语言和程序上，譬如C、C++的程序要调用某个动态链接库的某个方法，就会出现很明显的边界隔阂，还难以优化。这是因为<strong>主程序与动态链接库的代码在它们编译时是完全独立的，两者各自编译、优化自己的代码</strong>。这些代码的作者、编译的时间，以及编译器甚至很可能都是不同的，当出现跨链接库边界的调用时，那些理论上应该要做的优化——譬如做对调用方法的内联，就会执行起来相当的困难</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>编译优化技术</strong></p>
<ul>
<li>OpenJDK的官方Wiki上，HotSpot虚拟机设计团队列出了一个相对比较全面的、即时编译器中采用的优化技术列表（见P556）</li>
<li>前提：<strong>即时编译器对这些代码优化变换是建立在代码的中间表示或者是机器码之上的，绝不是直接在Java源码上去做的</strong></li>
<li>常见编译优化技术<ul>
<li>方法内联（方法替换）<ul>
<li>优点：一是去除方法调用的成本（如查找方法版本、建立栈帧等）；二是为其他优化建立良好的基础。方法内联膨胀之后可以便于在更大范围上进行后续的优化手段，可以获取更好的优化效果。因此各种编译器一般都会把内联优化放在优化序列最靠前的位置</li>
</ul>
</li>
<li>冗余访问消除（Redundant Loads Elimination）<ul>
<li>如果删除某段代码不会影响最终这个方法的返回结果，则删除</li>
</ul>
</li>
<li>复写传播（Copy Propagation）<ul>
<li>如果A变量不需要使用B变量间接表达，则删除B</li>
</ul>
</li>
<li>无用代码消除（Dead Code Elimination）<ul>
<li>无用代码可能是永远不会被执行的代码，也可能是完全没有意义的代码。因此它又被很形象地称为“Dead Code”</li>
</ul>
</li>
</ul>
</li>
<li>代表性编译优化：<ul>
<li>最重要的优化技术之一：方法内联<ul>
<li>方法内联重要且是其它优化技术的前提但是在java中本身很多代码是无法进行内联的</li>
<li><strong>无法内联的原因</strong>其实在第8章中讲解Java方法解析和分派调用的时候就已经解释过：只有使用invokespecial指令调用的私有方法、实例构造器、父类方法和使用invokestatic指令调用的静态方法才会在编译期进行解析。除了上述四种方法之外（最多再除去被final修饰的方法这种特殊情况，尽管它使用invokevirtual指令调用，但也是非虚方法，《Java语言规范》中明确说明了这点），其他的Java方法调用都必须在运行时进行方法接收者的多态选择，它们都有可能存在多于一个版本的方法接收者，简而言之，Java语言中默认的实例方法是虚方法。对于一个虚方法，编译器静态地去做内联的时候很难确定应该使用哪个方法版本，如果不依赖上下文，是无法确定b的实际类型是什么的。假如有ParentB和SubB是两个具有继承关系的父子类型，并且子类重写了父类的get()方法，那么b.get()是执行父类的get()方法还是子类的get()方法，这应该是根据实际类型动态分派的，而实际类型必须在实际运行到这一行代码时才能确定，编译器很难在编译时得出绝对准确的结论。更糟糕的情况是，由于Java提倡使用面向对象的方式进行编程，而Java对象的方法默认就是虚方法，可以说Java间接鼓励了程序员使用大量的虚方法来实现程序逻辑。根据上面的分析可知，内联与虚方法之间会产生“矛盾”，那是不是为了提高执行性能，就应该默认给每个方法都使用final关键字去修饰呢？C和C++语言的确是这样做的，默认的方法是非虚方法，如果需要用到多态，就用virtual关键字来修饰，但Java选择了在虚拟机中解决这个问题。</li>
</ul>
</li>
<li>最前沿的优化技术之一：逃逸分析</li>
<li>语言无关的经典优化技术之一：公共子表达式消除</li>
<li>语言相关的经典优化技术之一：数组边界检查消除</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十二章：Java内存模型和线程"><a href="#第十二章：Java内存模型和线程" class="headerlink" title="第十二章：Java内存模型和线程"></a>第十二章：Java内存模型和线程</h2><ul>
<li><p>每秒事务处理数（Transactions Per Second，TPS）</p>
</li>
<li><p>除了增加高速缓存之外，为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有指令重排序（Instruction Reorder）优化</p>
</li>
<li><p>JMM的意义：屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。在此之前，主流程序语言（如C和C++等）直接使用物理硬件和操作系统的内存模型。因此，由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错，所以在某些场景下必须针对不同的平台来编写程序</p>
</li>
<li><p>Java内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节。此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数</p>
</li>
<li><p>Java内存模型规定了所有的变量都存储在主内存（Main Memory），线程又各自拥有不同的工作内存，线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系</p>
</li>
<li><p>java堆中保存的数据</p>
<ul>
<li>对于HotSpot虚拟机来讲，Java堆保存了实例数据，Mark Word（存储对象哈希码、GC标志、GC年龄、同步锁等信息）、Klass Point（指向存储类型元数据的指针）及一些用于字节对齐补白的填充数据</li>
</ul>
</li>
<li><p>JMM定义了工作内存和主内存交换数据通过lock,unlock,read,load,use,assign,store,write八种基本操作（这八种操作都是原子性的），后为了简化，将其简化为read、write、lock和unlock四种，并且将处理时需要满足的条件简化为happen-before原则</p>
</li>
<li><p>volatile</p>
<ul>
<li>volatile是Java虚拟机提供的最轻量级的同步机制，保证可见性可以作为通知变量使用</li>
<li>volatile作用<ul>
<li>保证变量具有可见性（A线程更改后B线程能立马得知）</li>
<li>禁止指令重排序优化，通过添加内存屏障，使得重排序时不能把后面的指令重排序到内存屏障之前的位置</li>
</ul>
</li>
<li>虽然变量具有可见性，但由于递增运算并不是原子性的（根本原因在于Java里面的运算操作符并非原子操作），从字节码层面上已经很容易分析出并发失败的原因了：当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此时是正确的，但是在执行iconst_1、iadd这些指令的时候，其他线程可能已经把race的值改变了，而操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值同步回主内存之中</li>
<li>注意字节码也不一定是原子操作：一条字节码指令在解释执行时，解释器要运行许多行代码才能实现它的语义。如果是编译执行，一条字节码指令也可能转化成若干条本地机器码指令</li>
<li>volatile的同步机制的性能确实要优于锁（使用synchronized关键字或java.util.concurrent包里面的锁），但是由于虚拟机对锁实行的许多消除和优化，使得我们很难确切地说volatile就会比synchronized快上多少</li>
<li>针对long和double型变量的特殊规则，允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性，这就是所谓的“long和double的非原子性协定”（Non-Atomic Treatment of double and long Variables）但实际上64位机上不会出现问题，32位机上出现这种问题也十分罕见，所以不用因为这个原因专门声明对应volatile变量</li>
</ul>
</li>
<li><p>Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的</p>
<ul>
<li><p>原子性：</p>
<ul>
<li>由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write这六个，我们大致可以认为，基本数据类型的访问、读写都是具备原子性的（例外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）</li>
<li>如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了<strong>lock和unlock操作</strong>来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令<strong>monitorenter和monitorexit</strong>来隐式地使用这两个操作。这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性</li>
</ul>
</li>
<li><p>可见性：</p>
<ul>
<li>Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种<strong>依赖主内存作为传递媒介</strong>的方式来实现可见性的，无论是普通变量还是volatile变量都是如此。<strong>普通变量与volatile变量的区别</strong>是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新</li>
<li>除了volatile之外，Java还有两个关键字能实现可见性，它们是synchronized和final。同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的。而final关键字的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程中就能看见final字段的值。</li>
</ul>
</li>
<li><p>有序性</p>
<ul>
<li>Java程序中天然的有序性可以总结为一句话：<strong>如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的</strong><ul>
<li>前半句是指“线程内似表现为串行的语义”（Within-Thread As-If-SerialSemantics）</li>
<li>后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。</li>
</ul>
</li>
<li>Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入</li>
</ul>
</li>
<li><p>happen-before原则</p>
<ul>
<li><p>“先行发生”（Happens-Before）的原则。这个原则非常重要，它是判断数据是否存在竞争，<strong>线程是否安全</strong>的非常有用的手段，避免通过苦涩复杂的JMM来判断线程是否安全</p>
</li>
<li><p>定义：操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等（所以先行发生不意味着时间上真的先运行）</p>
</li>
<li><p>如果两个操作之间的关系不在happen-before原则中，并且无法从下列规则推导出来，则它们就没有顺序性保障，<strong>虚拟机可以对它们随意地进行重排序</strong>（简言之happen-before原则可以作为判断是否能重排序的规则（能重排序不代表一定重排序））</p>
</li>
<li><p>注意先行发生原则和时间没有关系，二者互不影响，详细见下分析</p>
<ul>
<li>示例一（先执行的不一定先行发生）</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221128144957798.png" srcset="/img/loading.gif" lazyload alt="image-20221125203205479"></p>
<ul>
<li>线程A先（时间上的先后）调用了setValue(1)，然后线程B调用了同一个对象的getValue()，那么线程B收到的返回值是什么?    答案：可能是0，也有可能是1</li>
<li>分析：由于两个方法分别由线程A和B调用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被volatile关键字修饰，所以volatile变量规则不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们可以判定，尽管线程A在操作时间上先于线程B，但是无法确定线程B中getValue()方法的返回结果，换句话说，这里面的操作不是线程安全的</li>
<li>解决方法：<ul>
<li>要么把getter&#x2F;setter方法都定义为synchronized方法，这样就可以套用管程锁定规则；</li>
<li>要么把value定义为volatile变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样就可以套用volatile变量规则来实现先行发生关系</li>
</ul>
</li>
<li>示例二（满足先行发生的不一定真的时间上先发生）</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221128145018987.png" srcset="/img/loading.gif" lazyload alt="image-20221125203607563"></p>
<ul>
<li>根据程序次序规则，“int i&#x3D;1”的操作先行发生于“int j&#x3D;2”，但是“int j&#x3D;2”的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程之中没有办法感知到这一点</li>
</ul>
</li>
</ul>
</li>
<li><p>线程相关</p>
<ul>
<li><p>Thread类与大部分的Java类库API有着显著差别，它的所有关键方法都被声明为Native。在Java类库API中，一个Native方法往往就意味着这个方法没有使用或无法使用平台无关的手段来实现（恰好也是java线程是映射到系统线程的体现）</p>
</li>
<li><p>实现线程主要有三种方式</p>
<ul>
<li><p><strong>使用内核线程实现（1：1实现）</strong></p>
<ul>
<li>使用内核线程实现的方式也被称为1：1实现。<strong>内核线程（Kernel-Level Thread，KLT）</strong>就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过<strong>操纵调度器（Scheduler）</strong>对线程进行调度，并负责将线程的任务映射到各个处理器上</li>
<li>每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就称为多线程内核（Multi-Threads Kernel）</li>
<li>程序一般不会直接使用内核线程，而是使用内核线程的一种高级接口——<strong>轻量级进程（LightWeight Process，LWP）</strong>，轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1：1的关系称为一对一的线程模型<ul>
<li>PS：概念上只要不是内核线程都应该被视为用户线程，但LWP是映射在KLT上的，不具有一般意义上的用户线程优点，故仍然被视为内核线程</li>
</ul>
</li>
</ul>
<img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125192746870.png" srcset="/img/loading.gif" lazyload alt="image-20221125192746870" style="zoom:67%;" />

<ul>
<li>优点：<ul>
<li>由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使其中某一个轻量级进程在系统调用中被阻塞了，也不会影响整个进程继续工作</li>
</ul>
</li>
<li>局限性：<ul>
<li>线程切换代价大：由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，<strong>需要在用户态（User Mode）和内核态（Kernel Mode）中来回切换</strong></li>
<li>线程的数量有限：每个轻量级进程都需要有一个内核线程的支持，因此<strong>轻量级进程要消耗一定的内核资源</strong>（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>使用用户线程实现（1：N实现）</strong></p>
<ul>
<li>优点：狭义上的用户线程指的是完全建立在用户空间的线程库上，<strong>系统内核不能感知到用户线程的存在及如何实现的。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也能够支持规模更大的线程数量</strong>，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型</li>
<li>局限性：成也萧何败也萧何，用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要由用户程序自己去处理。线程的创建、销毁、切换和调度都是用户必须考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如<strong>“阻塞如何处理”“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至有些是不可能实现的。因为使用用户线程实现的程序通常都比较复杂，除了有明确的需求外（譬如以前在不支持多线程的操作系统中的多线程程序、需要支持大规模线程数量的应用），一般的应用程序都不倾向使用用户线程。</strong>Java、Ruby等语言都曾经使用过用户线程，最终又都放弃了使用它。但是近年来许多新的、以高并发为卖点的编程语言又普遍支持了用户线程，譬如Golang、Erlang等，使得用户线程的使用率有所回升</li>
</ul>
<img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125194107906.png" srcset="/img/loading.gif" lazyload alt="image-20221125194122388" style="zoom:67%;" />
</li>
<li><p><strong>使用用户线程加轻量级进程混合实现（N：M实现）</strong></p>
<ul>
<li>线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现式，被称为N：M实现。在这种混合实现下，<strong>既存在用户线程，也存在轻量级进程</strong>。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，<strong>这大大降低了整个进程被完全阻塞的风险</strong>。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，是N：M的关系，如图12-5所示，这种就是多对多的线程模型</li>
<li>总结兼具了以上两种特点，能够使用灵活的用户线程，同时有轻量级进程不容易导致进程完全阻塞的优点<ul>
<li>N和M，在于可以有多个UT绑定在LWP上，也可以只有UT绑定在LWP上</li>
</ul>
</li>
</ul>
<img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125200903780.png" srcset="/img/loading.gif" lazyload alt="image-20221125194107906" style="zoom:67%;" />
</li>
<li><p>java线程的实现</p>
<ul>
<li>JDK 1.2以前：早期的Classic虚拟机上是基于一种被称为“绿色线程”（Green Threads）的用户线程实现的</li>
<li>从JDK 1.3起：“主流”平台上的“主流”商用Java虚拟机的线程模型普遍都被替换为基于操作系统原生线程模型来实现，即采用1：1的线程模型（当然也有其他虚拟就采用另外两种线程实现方式）</li>
</ul>
</li>
<li><p>java线程特点</p>
<ul>
<li>以HotSpot为例，它的每一个Java线程都是直接映射到一个操作系统原生线程来实现的，而且中间没有额外的间接结构，所以HotSpot自己是不会去干涉线程调度的（可以设置线程优先级给操作系统提供调度建议），全权交给底下操作系统去处理，所以何时冻结或唤醒线程、该给线程分配多少处理器执行时间、该把线程安排给哪个处理器核心去执行等，都是由操作系统完成的，也都是由操作系统全权决定的。</li>
<li>由于线程实现很大程度上取决于操作系统的实现，所以java虚拟机规范实际上并不在意是如何实现的，线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码和运行过程来说，这些差异都是完全透明的（看不见的，无所谓的）</li>
</ul>
</li>
</ul>
</li>
<li><p>java线程调度方式（线程调度是指系统为线程分配处理器使用权的过程）</p>
<ul>
<li><strong>协同式（Cooperative Threads-Scheduling）线程调度</strong><ul>
<li>优点：<ul>
<li>线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以一般没有什么线程同步的问题</li>
</ul>
</li>
<li>缺点：<ul>
<li>线程执行时间不可控制，甚至如果一个线程的代码编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。很久以前的Windows 3.x系统就是使用协同式来实现多进程多任务的，那是相当不稳定的，只要有一个进程坚持不让出处理器执行时间，就可能会导致整个系统崩溃</li>
</ul>
</li>
</ul>
</li>
<li><strong>抢占式（Preemptive Threads-Scheduling）线程调度（java的实现方式）</strong><ul>
<li>特点：<ul>
<li>线程的切换，运行时间都是由系统控制的，线程可以调用Thread::yield()方法主动让出运行时间，但是不能通过线程本身获取运行时间，在这种调度方式下不会有线程导致系统崩溃问题</li>
<li>虽然线程的调度是系统控制的，但是我们可以使用线程优先级来”建议“系统对于线程的青睐，Java语言一共设置了10个级别的线程优先级（Thread.MIN_PRIORITY至Thread.MAX_PRIORITY）<ul>
<li>优先级本身依赖于操作系统的实现，Solaris中线程有2147483648（2的31次幂）种优先级，但Windows中就只有七种优先级，所以可能存在一对多，多对一的情况</li>
<li>优先级本身不靠谱的原因<ul>
<li>由于优先级的映射问题，可能多个java优先级实际上映射的是同一个系统优先级</li>
<li>线程调度本质还是系统控制，系统可能因为优化等原因“擅自”改变运行顺序，如在Windows系统中存在一个叫“优先级推进器”的功能（Priority Boosting，当然它可以被关掉），大致作用是当系统发现一个线程被执行得特别频繁时，可能会越过线程优先级去为它分配执行时间，从而减少因为线程频繁切换而带来的性能损耗</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>java线程的状态转化</p>
<ul>
<li>Java语言定义了6种线程状态，在任意一个时间点中，<strong>一个线程只能有且只有其中的一种状态</strong>，并且可以通过特定的方法在不同状态之间转换</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125194122388.png" srcset="/img/loading.gif" lazyload alt="image-20221125200903780"></p>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221125200921258.png" srcset="/img/loading.gif" lazyload alt="image-20221125200921258"></p>
</li>
</ul>
</li>
<li><p>java和协程</p>
<ul>
<li>Java语言抽象出来隐藏了各种操作系统线程差异性的统一线程接口，这本是其优势，但是由于高并发场景的出现，这种模式出现了一些弊病</li>
<li>现代B&#x2F;S系统中一次对外部业务请求的响应，往往需要分布在不同机器上的大量服务共同协作来实现，这种服务细分的架构在<strong>减少单个服务复杂度、增加复用性</strong>的同时，也不可避免地<strong>增加了服务的数量</strong>，缩短了留给每个服务的响应时间。这要求每一个服务都必须在<strong>极短的时间</strong>内完成计算，这样组合多个服务的总耗时才不会太长；也要求每一个服务提供者都要能同时处理数量更庞大的请求，这样才不会出现请求由于某个服务被阻塞而出现等待</li>
<li>微服务架构下，java略显疲态：Java目前的并发编程机制就与上述架构趋势产生了一些矛盾，1：1的内核线程模型是如今Java虚拟机线程实现的主流选择，<strong>但是这种映射到操作系统上的线程天然的缺陷是切换、调度成本高昂，系统能容纳的线程数量也很有限</strong>。以前处理一个请求可以允许花费很长时间在单体应用中，具有这种线程切换的成本也是无伤大雅的，但现在在每个请求本身的执行时间变得很短、数量变得很多的前提下，用户线程切换的开销甚至可能会接近用于计算本身的开销，这就会造成严重的浪费</li>
</ul>
</li>
<li><p>切换内核线程为什么比切换用户线程成本要高？</p>
<ul>
<li>内核线程的调度成本主要来自于用户态与核心态之间的状态转换，而这两种状态转换的开销主要来自于<strong>响应中断、保护和恢复执行现场的成本</strong>，假设发生了  “  线程A -&gt; 系统中断 -&gt; 线程B  “ 过程</li>
<li>处理器要去执行线程A的程序代码时，并不是仅有代码程序就能跑得起来，程序是数据与代码的组合体，代码执行时还必须要有上下文数据的支撑。</li>
<li>而这里说的<strong>“上下文”</strong><ul>
<li>以<strong>程序员</strong>的角度来看，是<strong>方法调用过程中的各种局部的变量与资源</strong>；</li>
<li>以<strong>线程</strong>的角度来看，是<strong>方法的调用栈中存储的各类信息</strong>；</li>
<li>而以<strong>操作系统和硬件</strong>的角度来看，则是<strong>存储在内存、缓存和寄存器中的一个个具体数值</strong>。</li>
</ul>
</li>
<li>物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源，当中断发生，从线程A切换到线程B去执行之前，操作系统首先要把线程A的上下文数据妥善保管好，然后把寄存器、内存分页等恢复到线程B挂起时候的状态，这样线程B被重新激活后才能仿佛从来没有被挂起过。这种保护和恢复现场的工作，免不了涉及一系列数据在各种寄存器、缓存中的来回拷贝，当然不可能是一种轻量级的操作</li>
</ul>
</li>
<li><p>使用用户线程（协程）的好处</p>
<ul>
<li>如果说内核线程的切换开销是来自于保护和恢复现场的成本，那如果改为采用用户线程，这部分开销就能够省略掉吗？答案是“不能”。但是，一旦把保护、恢复现场及调度的工作从操作系统交到程序员手上，那我们就可以打开脑洞，通过玩出很多新的花样来缩减这些开销</li>
<li>由于最初多数的用户线程是被设计成协同式调度（Cooperative Scheduling）的，所以它有了一个别名——“协程”（Coroutine）。又由于<strong>这时候的协程会完整地做调用栈的保护、恢复工作</strong>（自己调度上下文的保护，恢复工作），所以今天也被称为“有栈协程”（Stackfull Coroutine），起这样的名字是为了便于跟后来的“无栈协程”（Stackless Coroutine）区分开。无栈协程不是本节的主角，不过还是可以简单提一下它的典型应用，即各种语言中的await、async、yield这类关键字。无栈协程本质上是一种有限状态机，状态保存在闭包里，自然比有栈协程恢复调用栈要轻量得多，但功能也相对更有限</li>
<li>协程的主要优势是轻量，无论是有栈协程还是无栈协程，都要比传统内核线程要轻量得多，在不进行特殊设定的情况下，则在64位Linux上HotSpot的线程栈容量默认是1MB，此外内核数据结构（Kernel Data Structures）还会额外消耗16KB内存。与之相对的，一个协程的栈通常在几百个字节到几KB之间</li>
</ul>
</li>
<li><p>使用用户线程（协程）的弊端</p>
<ul>
<li>协程当然也有它的局限，需要在应用层面实现的内容（调用栈、调度器这些）特别多</li>
<li>协程在最初，甚至在今天很多语言和框架中会被设计成协同式调度，这样在语言运行平台或者框架上的调度器就可以做得非常简单。不过有不少资料上显示，既然取了“协程”这样的名字，它们之间就一定以协同调度的方式工作（并不绝对，反例并不少见）</li>
</ul>
</li>
<li><p>java实现协程的难点</p>
<ul>
<li>到Java语言，还会有一些别的限制，譬如HotSpot这样的虚拟机，Java调用栈跟本地调用栈是做在一起的。如果在协程中调用了本地方法，还能否正常切换协程而不影响整个线程？另外，如果协程中遇传统的线程同步措施会怎样？譬如Kotlin提供的协程实现，一旦遭遇synchronize关键字，那挂起来的仍将是整个线程</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十三章：线程安全与锁优化"><a href="#第十三章：线程安全与锁优化" class="headerlink" title="第十三章：线程安全与锁优化"></a>第十三章：线程安全与锁优化</h2><ul>
<li><p>线程安全：</p>
<ul>
<li>当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那就称这个对象是线程安全的</li>
</ul>
</li>
<li><p>可操作的数据的安全状态（从强到弱）</p>
<ul>
<li><strong>不可变、绝对线程安全、相对线程安全、线程兼容和线程对立</strong></li>
<li>不可变：<ul>
<li>“不可变”带来的安全性是最直接、最纯粹的</li>
<li>在Java类库API中符合不可变要求的类型，除了上面提到的String之外，常用的还有枚举类型及java.lang.Number的部分子类，如Long和Double等数值包装类型、BigInteger和BigDecimal等大数据类型。但同为Number子类型的原子类AtomicInteger和AtomicLong则是可变的（TODO 为什么这两个是可变的）</li>
</ul>
</li>
<li>绝对线程安全（TODO 和相对线程安全的对比）：</li>
<li>相对线程安全：<ul>
<li>相对线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性</li>
<li>在Java语言中，大部分声称线程安全的类都属于这种类型，例如Vector、HashTable、Collections的synchronizedCollection()方法包装的集合等</li>
</ul>
</li>
<li>线程兼容：<ul>
<li>线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。我们平常说一个类不是线程安全的，通常就是指这种情况。Java类库API中大部分的类都是线程兼容的，如与前面的Vector和HashTable相对应的集合类ArrayList和HashMap等</li>
</ul>
</li>
<li>线程对立<ul>
<li>线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码</li>
</ul>
</li>
</ul>
</li>
<li><p>线程安全的实现方法：</p>
<ul>
<li><p><strong>一、互斥同步：</strong></p>
<ul>
<li>是一种最常见也是最主要的并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一条（或者是一些，当使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是常见的互斥实现方式。因此在“互斥同步”这四个字里面，互斥是因，同步是果；互斥是方法，同步是目的</li>
<li>互斥同步的应用<ul>
<li>synchronized关键字<ul>
<li>最常见的互斥同步的应用是<strong>synchronized关键字</strong>，这是一种块结构（BlockStructured）的同步语法。synchronized关键字经过Javac编译之后，会在同步块的前后分别形成<strong>monitorenter和monitorexit</strong>这两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。<strong>如果Java源码中的synchronized明确指定了对象参数</strong>，那就以<strong>这个对象的引用作为reference</strong>；<strong>如果没有明确指定</strong>，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是<strong>取代码所在的对象实例还是取类型对应的Class对象</strong>来作为线程要持有的锁</li>
<li>根据《Java虚拟机规范》的要求，在执行monitorenter指令时，首先要去尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行monitorexit指令时会将锁计数器的值减一。一旦计数器的值为零，锁随即就被释放了。如果获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止</li>
<li>被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。</li>
<li>被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。</li>
<li>synchronized是Java语言中一个重量级的操作，有经验的程序员都只会在确实必要的情况下才使用这种操作（在一些简单的方法中使用synchronized方法可能本身运行的时间还赶不上切换线程的消耗）。而虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，以避免频繁地切入核心态之中</li>
</ul>
</li>
<li>重入锁（ReentrantLock）<ul>
<li>java.util.concurrent.locks.Lock接口便成了Java的另一种全新的互斥同步手段。基于Lock接口，用户能够以非块结构（Non-Block Structured）来实现互斥同步，从而摆脱了语言特性的束缚，改为在类库层面去实现同步，是各种锁的实现基础</li>
<li>重入锁（ReentrantLock）是Lock接口最常见的一种实现，顾名思义，<strong>它与synchronized一样是可重入的</strong>。在基本用法上，<strong>ReentrantLock也与synchronized很相似</strong>，只是代码写法上稍有区别而已。不过，ReentrantLock与synchronized相比增加了一些高级功能，主要有以下三项：<ul>
<li><strong>等待可中断：</strong>是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。</li>
<li><strong>公平锁：</strong>是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁，将会导致ReentrantLock的性能急剧下降，会明显影响吞吐量</li>
<li><strong>锁绑定多个条件：</strong>是指一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized中，锁对象的wait()跟它的notify()或者notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而ReentrantLock则无须这样做，多次调用newCondition()方法即可。</li>
</ul>
</li>
<li>ReentrantLock在功能上是synchronized的超集，在性能上又至少不会弱于synchronized，看起来好像完爆synchronized，但还是在两者都能使用的时候选择synchronized，原因如下<ul>
<li><strong>简单易用：</strong>synchronized是在Java语法层面的同步，足够清晰，也足够简单。每个Java程序员都熟悉synchronized，但J.U.C中的Lock接口则并非如此。因此在只需要基础的同步功能时，更推荐synchronized</li>
<li><strong>保证释放资源：</strong>Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确保即使出现异常，锁也能被自动释放</li>
<li><strong>synchronized更好优化的天性：</strong>尽管在JDK 5时代ReentrantLock曾经在性能上领先过synchronized，但这已经是十多年之前的胜利了。从长远来看，Java虚拟机更容易针对synchronized来进行优化，因为Java虚拟机可以在线程和对象的元数据中记录synchronized中锁的相关信息，而使用J.U.C中的Lock的话，Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>二、非阻塞同步</strong></p>
<ul>
<li><p>互斥同步面临的主要问题是<strong>进行线程阻塞和唤醒</strong>所带来的性能开销，因此这种同步也被称为<strong>阻塞同步</strong>（Blocking Synchronization）。从解决问题的方式上看，互斥同步属于一种悲观的并发策略，<strong>其总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享的数据是否真的会出现竞争，它都会进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）</strong>，这将会导致用户态到核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等开销。随着硬件指令集的发展，我们已经有了另外一个选择：<strong>基于冲突检测的乐观并发策略</strong>，<strong>通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。</strong>这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为<strong>非阻塞同步（Non-Blocking Synchronization）</strong>，使用这种措施的代码也常被称为<strong>无锁（Lock-Free）编程</strong></p>
</li>
<li><p>要求操作和冲突检测这两个步骤具备原子性。靠什么来保证原子性？如果这里再使用互斥同步来保证就完全失去意义了，所以我们只能靠硬件来实现这件事情，硬件保证某些从语义上看起来需要多次操作的行为可以只通过一条处理器指令就能完成，这类指令常用的有：（无论硬件底层使用的命令类型如何，最终暴露出来的都是CAS操作）</p>
<ul>
<li>在IA64、x86指令集中有用cmpxchg指令完成的CAS功能，</li>
<li>在SPARC-TSO中也有用casa指令实现的，</li>
<li>而在ARM和PowerPC架构下，则需要使用一对ldrex&#x2F;strex指令来完成LL&#x2F;SC的功能</li>
</ul>
</li>
<li><p><strong>CAS指令</strong>需要有三个操作数，分别是内存位置（在Java中可以简单地理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和准备设置的新值（用B表示）。CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则它就不执行更新。但是，不管是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作，执行期间不会被其他线程中断</p>
</li>
<li><p>在java9之前，是不允许用户调用Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供CAS操作的HotSpot虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是无条件内联进去了（并发包中的整数原子类的compareAndSet()和getAndIncrement()等方法都使用了Unsafe类的CAS），由于Unsafe类中的方法限定了只有启动类加载器加载的类才能调用CAS操作，所以在JAVA9之前除非使用反射这样的奇技淫巧否则无法调用，直到JDK 9之后，Java类库才在VarHandle类里开放了面向用户程序使用的CAS操作</p>
</li>
<li><pre><code class="java">//1.8中的incrementAndGet方法
public final int incrementAndGet() &#123;
        return U.getAndAddInt(this, VALUE, 1) + 1;
    &#125;

public final int getAndAddInt(Object o, long offset, int delta) &#123;
        int v;
        do &#123;  //不断进行CAS操作
            v = getIntVolatile(o, offset);
        &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta));
        return v;
    &#125;
    
public final boolean weakCompareAndSetInt(Object o, long offset,
                                              int expected,
                                              int x) &#123;
        return compareAndSetInt(o, offset, expected, x);
    &#125;

//本地方法
public final native boolean compareAndSetInt(Object o, long offset,
                                                 int expected,
                                                 int x);
</code></pre>
</li>
<li><p>ABA问题：J.U.C包为了解决这个问题（版本号或者时间戳），提供了一个<strong>带有标记的原子引用类AtomicStampedReference</strong>，它可以通过控制变量值的版本来保证CAS的正确性。不过目前来说这个类处于相当鸡肋的位置，<strong>大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更为高效</strong></p>
</li>
</ul>
</li>
<li><p><strong>三、无同步方法</strong></p>
<ul>
<li>解决线程安全的根源，即避免出现线程不安全的情况</li>
<li>常见应用<ul>
<li><strong>可重入代码（Reentrant Code）：</strong><ul>
<li>这种代码又称纯代码（Pure Code），是指可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误，也不会对结果有所影响。在特指多线程的上下文语境里（不涉及信号量等因素），我们可以认为可重入代码是线程安全代码的一个真子集，这意味着相对线程安全来说，<strong>可重入性是更为基础的特性，它可以保证代码线程安全，即所有可重入的代码都是线程安全的，但并非所有的线程安全的代码都是可重入的。</strong></li>
<li>特点：不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等</li>
<li>判断方式：如果一个方法的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的（醉了，实际上就是对重用这个词解释了一下）</li>
</ul>
</li>
<li><strong>线程本地存储（Thread Local Storage）：</strong><ul>
<li>如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。（既然临界数据会导致线程不安全的问题，那么我干脆放到同一个线程中）</li>
<li>实际应用：<strong>大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程限制在一个线程中消费完，其中最重要的一种应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式</strong>，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题</li>
<li>声明一个多线程共享的变量可以使用volatile修饰符，声明一个变量为线程独有的可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>锁优化技术</p>
<ul>
<li><p>为了在线程之间更高效地共享数据及解决竞争问题，从而提高程序的执行效率引入了许多锁优化技术，适应性自旋（Adaptive Spinning）、锁消除（LockElimination）、锁膨胀（Lock Coarsening）、轻量级锁（Lightweight Locking）、偏向锁（BiasedLocking）等</p>
</li>
<li><p><strong>自旋锁：</strong></p>
<ul>
<li>由于线程本身的切换开销很大，所以当某个线程请求锁的时候无法成功时，不将这个锁进行挂起而是让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只须让线程执行一个忙循环（自旋）</li>
<li>适用场景：自旋等待时间短，不适合自旋等待时间长的情况（这种情况考虑使用自适应自旋）</li>
<li>使用参数：<ul>
<li>-XX：+UseSpinning参数来开启，在JDK 6中就已经改为默认开启了</li>
<li>-XX：PreBlockSpin来自行更改自旋的次数，默认是10次</li>
</ul>
</li>
<li>自适应自旋<ul>
<li>自适应意味着自旋的时间不再是固定的了，而是<strong>由前一次在同一个锁上的自旋时间及锁的拥有者的状态</strong>来决定的。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间，比如持续100次忙循环。另一方面，如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行时间的增长及性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越精准，虚拟机就会变得越来越“聪明”了</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>锁消除</strong></p>
<ul>
<li>锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸分析技术），如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行</li>
<li>同步代码块的出现频率实际上很高，即使用户没有显示的调用同步代码，实际上在运行过程中也是有很多同步代码和同步代码块优化</li>
<li>应用场景<ul>
<li><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126130001272.png" srcset="/img/loading.gif" lazyload alt="image-20221126125054413"></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>锁粗化</strong></p>
<ul>
<li>原则上，我们在编写代码的时候，总是推荐将同步块的作用范围<strong>限制得尽量小</strong>——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等待锁的线程也能尽可能快地拿到锁</li>
<li>大多数情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗</li>
<li>应用场景：连续的append()方法就属于这类情况。如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部，就是扩展到第一个append()操作之前直至最后一个append()操作之后，这样只需要加锁一次就可以了</li>
</ul>
</li>
<li><p><strong>轻量级锁</strong></p>
<ul>
<li>轻量级锁是JDK 6时加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就被称为“重量级”锁。不过，需要强调一点<strong>，轻量级锁并不是用来代替重量级锁的，</strong>它设计的初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗</li>
<li>轻量级锁是基于对于对象的Mark Word 实现的，而轻量级锁的加锁解锁操作实际上都是基于CAS实现的</li>
<li>Mark Word：是一个非固定的动态数据结构，以便在极小的空间内存储尽量多的信息。它会根据对象的状态复用自己的存储空间</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126125628190.png" srcset="/img/loading.gif" lazyload alt="image-20221126125628190"></p>
<ul>
<li><p><strong>轻量级锁的工作流程</strong></p>
<ul>
<li>1、在代码即将进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方为这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线程堆栈与对象头的状态如图13-3</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126125826690.png" srcset="/img/loading.gif" lazyload alt="image-20221126125826690"></p>
<ul>
<li>2、然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将转变为“00”，表示此对象处于轻量级锁定状态。这时候线程堆栈与对象头的状态如图13-4所示<ul>
<li><strong>如果这个更新操作失败了，那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。</strong>虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。如果出现两条以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要膨胀为重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也必须进入阻塞状态</li>
</ul>
</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126125054413.png" srcset="/img/loading.gif" lazyload alt="image-20221126130001272"></p>
<ul>
<li>3、轻量级锁的解锁过程（把原本存在栈帧中的Mark Word换回来）：上面描述的是轻量级锁的加锁过程，它的解锁过程也同样是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的DisplacedMark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程</li>
</ul>
</li>
<li><p>轻量级锁的应用分析：</p>
<ul>
<li>轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销外，还额外发生了CAS操作的开销。因此在<strong>有竞争</strong>的情况下，轻量级锁反而会比传统的重量级锁更慢（适用于竞争量真的小的情况）</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>偏向锁</strong></p>
<ul>
<li>偏向锁也是JDK 6中引入的一项锁优化措施，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不去做了（我摊牌了，我就赌所有的操作一般都不会有并发请求，所以我偏向第一个获取锁的线程，直到有别的线程来读取这个对象我才进行相关同步操作）</li>
<li>偏向锁中的“偏”，就是偏心的“偏”、偏袒的“偏”。它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。</li>
<li>假设当前虚拟机启用了偏向锁（<strong>启用参数-XX：+UseBiased Locking，默认启动</strong>），<strong>那么当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设置为“01”、把偏向模式设置为“1”，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作</strong>（例如加锁、解锁及对Mark Word的更新操作等）</li>
<li><strong>一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束</strong>。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“0”），撤销后标志位恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就按照上面介绍的轻量级锁那样去执行。偏向锁、轻量级锁的状态转化及对象Mark Word的关系如图13-5所示。</li>
</ul>
<p><img src="http://typora0418.oss-cn-hangzhou.aliyuncs.com/img/image-20221126161740653.png" srcset="/img/loading.gif" lazyload alt="image-20221126161740653"></p>
<ul>
<li><p>不用担心使用偏向锁时由于线程id和epoch的位置占据了hash值，因为线程ID和hashcode本身就是势不两立的</p>
<ul>
<li><p>在Java语言里面一个对象如果计算过哈希码，就应该一直保持该值不变（强烈推荐但不强制，因为用户可以重载hashCode()方法按自己的意愿返回哈希码），否则很多依赖对象哈希码的API都可能存在出错风险。而作为绝大多数对象哈希码来源的Object::hashCode()方法，返回的是对象的一致性哈希码（Identity Hash Code），这个值是能强制保证不变的，它通过在对象头中存储计算结果来保证第一次计算之后，再次调用该方法取到的哈希码值永远不会再发生改变。因此，当一个对象已经计算过一致性哈希码后，它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态，又收到需要计算其一致性哈希码请求[1]时，它的偏向状态会被立即撤销，并且锁会膨胀为重量级锁。在重量级锁</p>
<p>的实现中，对象头指向了重量级锁的位置，代表重量级锁的ObjectMonitor类里有字段可以记录非加锁状态（标志位为“01”）下的Mark Word，其中自然可以存储原来的哈希码</p>
</li>
</ul>
</li>
<li><p>偏向锁可以提高带有同步但无竞争的程序性能，但它同样是一个带有效益权衡（Trade Off）性质的优化，也就是说它并非总是对程序运行有利。如果程序中大多数的锁都总是被多个不同的线程访问，那偏向模式就是多余的。在具体问题具体分析的前提下，有时候使用参数-XX：-UseBiasedLocking来禁止偏向锁优化反而可以提升性能（和CAS操作有一样的弊端，如果这个资源真的是被多个线程并发处理的话，那么最好还是不要用偏向锁（多此一举））</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div></div>
      <div>http://example.com/2022/10/13/深入理解java虚拟机笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年10月13日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/02/20/%E9%9D%A2%E8%AF%95%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/" title="">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
